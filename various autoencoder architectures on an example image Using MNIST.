import numpy as np 
import matplotlib.pyplot as plt 
from keras.datasets import mnist 
from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, 
Reshape, LSTM, RepeatVector, TimeDistributed 
from keras.models import Model from keras import regularizers 
from tensorflow.keras import layers 
from tensorflow.keras import backend as K 
(x_train,_),(x_test,_)=mnist.load_data() 
x_train=x_train.astype('float32') / 255 
x_test=x_test.astype('float32')/255 
x_train_fc = x_train.reshape((len(x_train), np.prod(x_train.shape[1:]))) 
x_test_fc = x_test.reshape((len(x_test), np.prod(x_test.shape[1:]))) 
input_shape = (28, 28, 1) 

# Define the fully connected autoencoder 
input_fc = Input(shape=(784,)) 
encoded_fc = Dense(32, activation='relu')(input_fc) 
decoded_fc = Dense(784, activation='sigmoid')(encoded_fc) 
autoencoder_fc = Model(input_fc, decoded_fc) 
  
# Define the sparse autoencoder 
input_sparse = Input(shape=(784,)) 
encoded_sparse 	= 	Dense(32, 	activation='relu', 	activity_regularizer=regularizers.l1(10e-
5))(input_sparse) 
decoded_sparse = Dense(784, activation='sigmoid')(encoded_sparse) 
autoencoder_sparse = Model(input_sparse, decoded_sparse) 

# Define the recurrent autoencoder 
input_rnn = Input(shape=(28, 28)) 
encoded_rnn = LSTM(32)(input_rnn) 
decoded_rnn = RepeatVector(28)(encoded_rnn) 
decoded_rnn = LSTM(32, return_sequences=True)(decoded_rnn) 
decoded_rnn = TimeDistributed(Dense(28, activation='sigmoid'))(decoded_rnn) 
autoencoder_rnn = Model(input_rnn, decoded_rnn) 

# Define the variational autoencoder 
input_vae = Input(shape=(784,)) 
encoded_vae = Dense(256, activation='relu')(input_vae) 
z_mean = Dense(2)(encoded_vae) 
z_log_var = Dense(2)(encoded_vae)

# Define the Vanilla Autoencoder 
input_vanilla = Input(shape=(784,)) 
# Example for flattened MNIST images (28*28) 
encoded_vanilla = Dense(128, activation='relu')(input_vanilla) 
encoded_vanilla = Dense(32, activation='relu')(encoded_vanilla) 
# Bottleneck/latent space 
decoded_vanilla = Dense(128, activation='relu')(encoded_vanilla) 
decoded_vanilla = Dense(784, activation='sigmoid')(decoded_vanilla)  

# Reconstruct to original input dim 
autoencoder_vanilla = Model(input_vanilla, decoded_vanilla)

#Define the Contrastive autoencoder 
input_contrastive_ae = Input(shape=(784,)) 
encoded_contrastive_ae = Dense(256, activation='relu')(input_contrastive_ae) 
encoded_contrastive_ae = Dense(32, activation='relu')(encoded_contrastive_ae) 
decoded_contrastive_ae = Dense(256, activation='relu')(encoded_contrastive_ae) 
decoded_contrastive_ae = Dense(784, activation='sigmoid')(decoded_contrastive_ae) 
autoencoder_contrastive = Model(input_contrastive_ae, decoded_contrastive_ae) 

#Define the Denoisy autoencoder 
input_denoising_ae = Input(shape=(784,)) 
encoded_denoising_ae = Dense(128, activation='relu')(input_denoising_ae) 
encoded_denoising_ae = Dense(32, activation='relu')(encoded_denoising_ae) 
decoded_denoising_ae = Dense(128, activation='relu')(encoded_denoising_ae) 
decoded_denoising_ae = Dense(784, activation='sigmoid')(decoded_denoising_ae) 
autoencoder_denoising = Model(input_denoising_ae, decoded_denoising_ae) 
  
# Define the convolutional autoencoder 
input_cnn = Input(shape=input_shape) 
x_cnn = Conv2D(16, (3, 3), activation='relu', padding='same')(input_cnn) 
x_cnn = MaxPooling2D((2, 2), padding='same')(x_cnn) 
x_cnn = Conv2D(8, (3, 3), activation='relu', padding='same')(x_cnn) 
x_cnn = MaxPooling2D((2, 2), padding='same')(x_cnn) 
x_cnn = Conv2D(8, (3, 3), activation='relu', padding='same')(x_cnn) 
encoded_cnn = MaxPooling2D((2, 2), padding='same')(x_cnn) 
x_cnn = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded_cnn) 
x_cnn = UpSampling2D((2, 2))(x_cnn) 
x_cnn = Conv2D(8, (3, 3), activation='relu', padding='same')(x_cnn) 
x_cnn = UpSampling2D((2, 2))(x_cnn)
x_cnn = Conv2D(16, (3, 3), activation='relu')(x_cnn) 
x_cnn = UpSampling2D((2, 2))(x_cnn) 
decoded_cnn = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x_cnn) 
autoencoder_cnn = Model(input_cnn, decoded_cnn) 

# Define a sampling function to sample from the learned distribution def sampling(args): 
z_mean, z_log_var = args     
epsilon = K.random_normal(shape=(K.shape(z_mean)[0], 2)) 
return z_mean + K.exp(0.5 * z_log_var) * epsilon 
z = layers.Lambda(sampling)([z_mean, z_log_var]) 
decoded_vae = Dense(784, activation='sigmoid')(z) 
autoencoder_vae = Model(input_vae, decoded_vae) 

# Compile all the autoencoders 
autoencoder_fc.compile(optimizer='adam', loss='binary_crossentropy') 
autoencoder_cnn.compile(optimizer='adam', loss='binary_crossentropy') 
autoencoder_sparse.compile(optimizer='adam', loss='binary_crossentropy') 
autoencoder_rnn.compile(optimizer='adam', loss='binary_crossentropy') 
autoencoder_vae.compile(optimizer='adam', loss='binary_crossentropy') 
autoencoder_vanilla.compile(optimizer='adam', loss='binary_crossentropy') 
autoencoder_contrastive.compile(optimizer='adam', loss='binary_crossentropy') 
autoencoder_denoising.compile(optimizer='adam', loss='binary_crossentropy') 
import matplotlib.pyplot as plt import numpy as np 

# Load an example image 
x = x_test[0] 
x_fc_pred = autoencoder_fc.predict(np.expand_dims(x.flatten(), axis=0)).reshape(28, 28) 
x_cnn_pred = autoencoder_cnn.predict(np.expand_dims(x, axis=0)).reshape(28, 28) 
x_sparse_pred=autoencoder_sparse.predict(np.expand_dims(x.flatten(),axis=0)).reshape(28,28) 
x_rnn_pred = autoencoder_rnn.predict(np.expand_dims(x, axis=0)).reshape(28, 28) 
x_vae_pred = autoencoder_vae.predict(np.expand_dims(x.flatten(), axis=0)).reshape(28, 28) 
x_vanilla_pred = autoencoder_vanilla.predict(np.expand_dims(x.flatten(), axis=0)).reshape(28, 28) 
x_contrast_pred 	= autoencoder_contrastive.predict(np.expand_dims(x.flatten(), axis=0)).reshape(28, 28) 
x_denoising_pred 	= 	autoencoder_denoising.predict(np.expand_dims(x.flatten(), axis=0)).reshape(28, 28) 

# Plot the original image and the predicted outputs 
import matplotlib.pyplot as plt 
fig, axs = plt.subplots(1, 9, figsize=(18, 3)) 
# Increased to 9 subplots for the new AE 
axs[0].imshow(x, cmap='gray') 
axs[0].set_title('Original') axs[1].imshow(x_fc_pred, cmap='gray') 
axs[1].set_title('Fully Connected AE') axs[2].imshow(x_cnn_pred, cmap='gray') 
axs[2].set_title('Convolutional AE') axs[3].imshow(x_sparse_pred, cmap='gray') 
axs[3].set_title('Sparse AE') axs[4].imshow(x_rnn_pred, cmap='gray') 
axs[4].set_title('Recurrent AE') axs[5].imshow(x_vae_pred, cmap='gray') 
axs[5].set_title('Variational AE') axs[6].imshow(x_fc_pred, cmap='gray') 
axs[6].set_title('Vanilla AE') axs[7].imshow(x_contrast_pred, cmap='gray') 
axs[7].set_title('Contrast AE') axs[8].imshow(x_denoising_pred, cmap='gray') 
# Assuming 
x_denoising_pred exists axs[8].set_title('Denoising AE')
plt.tight_layout() 
plt.show() 



  





